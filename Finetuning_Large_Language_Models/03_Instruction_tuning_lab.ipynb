{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKn-Y_Pk9WjC"
      },
      "source": [
        "# Instruction-tuning"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets jsonlines llama_cpp transformers"
      ],
      "metadata": {
        "id": "nrZmNEyherkh",
        "outputId": "cb3832f4-88c5-452e-99c5-34f4481a1249",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.3.2-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.10.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.12)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.3.2-py3-none-any.whl (485 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.4/485.4 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, dill, multiprocess, datasets\n",
            "Successfully installed datasets-3.3.2 dill-0.3.8 multiprocess-0.70.16 xxhash-3.5.0\n",
            "Collecting jsonlines\n",
            "  Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonlines) (25.1.0)\n",
            "Downloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
            "Installing collected packages: jsonlines\n",
            "Successfully installed jsonlines-4.0.0\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement llama_cpp (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for llama_cpp\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "height": 183,
        "id": "YwB8OLqiflAl",
        "outputId": "323ab0ae-ddda-4dbf-9b3b-86f7513421fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'llama_cpp'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-7880031cf800>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpprint\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpprint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mllama_cpp\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLlama\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m#from Llama import BasicModelRunner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoModelForCausalLM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'llama_cpp'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import itertools\n",
        "import jsonlines\n",
        "\n",
        "from datasets import load_dataset\n",
        "from pprint import pprint\n",
        "\n",
        "#from llama_cpp import Llama\n",
        "from llama import BasicModelRunner\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Van12K4UeqKc"
      },
      "source": [
        "### Load instruction tuned dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 47,
        "id": "qyFHHrzpeqKc",
        "outputId": "b796c666-47d4-4650-ebfe-0a8b7e281486",
        "colab": {
          "referenced_widgets": [
            "8a377c1dee784d36982e81da28812e17"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8a377c1dee784d36982e81da28812e17",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/7.47k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "instruction_tuned_dataset = load_dataset(\"tatsu-lab/alpaca\", split=\"train\", streaming=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 115,
        "id": "bjfwnJQJeqKd",
        "outputId": "e122bb61-2540-4b1f-be0f-417dd5c9c36c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Instruction-tuned dataset:\n",
            "{'instruction': 'Give three tips for staying healthy.', 'input': '', 'output': '1.Eat a balanced diet and make sure to include plenty of fruits and vegetables. \\n2. Exercise regularly to keep your body active and strong. \\n3. Get enough sleep and maintain a consistent sleep schedule.', 'text': 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nGive three tips for staying healthy.\\n\\n### Response:\\n1.Eat a balanced diet and make sure to include plenty of fruits and vegetables. \\n2. Exercise regularly to keep your body active and strong. \\n3. Get enough sleep and maintain a consistent sleep schedule.'}\n",
            "{'instruction': 'What are the three primary colors?', 'input': '', 'output': 'The three primary colors are red, blue, and yellow.', 'text': 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nWhat are the three primary colors?\\n\\n### Response:\\nThe three primary colors are red, blue, and yellow.'}\n",
            "{'instruction': 'Describe the structure of an atom.', 'input': '', 'output': 'An atom is made up of a nucleus, which contains protons and neutrons, surrounded by electrons that travel in orbits around the nucleus. The protons and neutrons have a positive charge, while the electrons have a negative charge, resulting in an overall neutral atom. The number of each particle determines the atomic number and the type of atom.', 'text': 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nDescribe the structure of an atom.\\n\\n### Response:\\nAn atom is made up of a nucleus, which contains protons and neutrons, surrounded by electrons that travel in orbits around the nucleus. The protons and neutrons have a positive charge, while the electrons have a negative charge, resulting in an overall neutral atom. The number of each particle determines the atomic number and the type of atom.'}\n",
            "{'instruction': 'How can we reduce air pollution?', 'input': '', 'output': 'There are a number of ways to reduce air pollution, such as shifting to renewable energy sources, encouraging the use of public transportation, prohibiting the burning of fossil fuels, implementing policies to reduce emissions from industrial sources, and implementing vehicle emissions standards. Additionally, individuals can do their part to reduce air pollution by reducing car use, avoiding burning materials such as wood, and changing to energy efficient appliances.', 'text': 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nHow can we reduce air pollution?\\n\\n### Response:\\nThere are a number of ways to reduce air pollution, such as shifting to renewable energy sources, encouraging the use of public transportation, prohibiting the burning of fossil fuels, implementing policies to reduce emissions from industrial sources, and implementing vehicle emissions standards. Additionally, individuals can do their part to reduce air pollution by reducing car use, avoiding burning materials such as wood, and changing to energy efficient appliances.'}\n",
            "{'instruction': 'Describe a time when you had to make a difficult decision.', 'input': '', 'output': 'I had to make a difficult decision when I was working as a project manager at a construction company. I was in charge of a project that needed to be completed by a certain date in order to meet the client’s expectations. However, due to unexpected delays, we were not able to meet the deadline and so I had to make a difficult decision. I decided to extend the deadline, but I had to stretch the team’s resources even further and increase the budget. Although it was a risky decision, I ultimately decided to go ahead with it to ensure that the project was completed on time and that the client’s expectations were met. The project was eventually successfully completed and this was seen as a testament to my leadership and decision-making abilities.', 'text': 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nDescribe a time when you had to make a difficult decision.\\n\\n### Response:\\nI had to make a difficult decision when I was working as a project manager at a construction company. I was in charge of a project that needed to be completed by a certain date in order to meet the client’s expectations. However, due to unexpected delays, we were not able to meet the deadline and so I had to make a difficult decision. I decided to extend the deadline, but I had to stretch the team’s resources even further and increase the budget. Although it was a risky decision, I ultimately decided to go ahead with it to ensure that the project was completed on time and that the client’s expectations were met. The project was eventually successfully completed and this was seen as a testament to my leadership and decision-making abilities.'}\n"
          ]
        }
      ],
      "source": [
        "m = 5\n",
        "print(\"Instruction-tuned dataset:\")\n",
        "top_m = list(itertools.islice(instruction_tuned_dataset, m))\n",
        "for j in top_m:\n",
        "  print(j)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsEuhee1eqKd"
      },
      "source": [
        "### Two prompt templates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 302,
        "id": "_L47R-lNeqKe"
      },
      "outputs": [],
      "source": [
        "prompt_template_with_input = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
        "\n",
        "### Instruction:\n",
        "{instruction}\n",
        "\n",
        "### Input:\n",
        "{input}\n",
        "\n",
        "### Response:\"\"\"\n",
        "\n",
        "prompt_template_without_input = \"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
        "\n",
        "### Instruction:\n",
        "{instruction}\n",
        "\n",
        "### Response:\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSNXA_BKeqKe"
      },
      "source": [
        "### Hydrate prompts (add data to prompts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 183,
        "id": "g8GKsMiGeqKf"
      },
      "outputs": [],
      "source": [
        "processed_data = []\n",
        "for j in top_m:\n",
        "  if not j[\"input\"]:\n",
        "    processed_prompt = prompt_template_without_input.format(instruction=j[\"instruction\"])\n",
        "  else:\n",
        "    processed_prompt = prompt_template_with_input.format(instruction=j[\"instruction\"], input=j[\"input\"])\n",
        "\n",
        "  processed_data.append({\"input\": processed_prompt, \"output\": j[\"output\"]})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 30,
        "id": "WRCV3d9veqKg",
        "outputId": "b1287ef5-1a9b-412c-84fb-f39dc910b77a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input': 'Below is an instruction that describes a task. Write a response '\n",
            "          'that appropriately completes the request.\\n'\n",
            "          '\\n'\n",
            "          '### Instruction:\\n'\n",
            "          'Give three tips for staying healthy.\\n'\n",
            "          '\\n'\n",
            "          '### Response:',\n",
            " 'output': '1.Eat a balanced diet and make sure to include plenty of fruits '\n",
            "           'and vegetables. \\n'\n",
            "           '2. Exercise regularly to keep your body active and strong. \\n'\n",
            "           '3. Get enough sleep and maintain a consistent sleep schedule.'}\n"
          ]
        }
      ],
      "source": [
        "pprint(processed_data[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kD8PpfdDeqKg"
      },
      "source": [
        "### Save data to jsonl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 64,
        "id": "rdeam10beqKh"
      },
      "outputs": [],
      "source": [
        "with jsonlines.open(f'alpaca_processed.jsonl', 'w') as writer:\n",
        "    writer.write_all(processed_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7LfpPGMeqKh"
      },
      "source": [
        "### Compare non-instruction-tuned vs. instruction-tuned models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 64,
        "id": "8wz88h_seqKh",
        "outputId": "c8685a9a-4304-4c92-ab42-95e8d3ea441a",
        "colab": {
          "referenced_widgets": [
            "92d9144ef37e42468f4ad6ee0758060e",
            "f342c3c20ba2421c84ba57032cbd70a9",
            "2b77bd5ff64347aab7097a643538372c",
            "387b477651524780b1493d0f79888aa7",
            "609236e3c97f4c9f84b4bd14c999e7e5"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "92d9144ef37e42468f4ad6ee0758060e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/388 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f342c3c20ba2421c84ba57032cbd70a9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2b77bd5ff64347aab7097a643538372c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/12.7M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "387b477651524780b1493d0f79888aa7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "609236e3c97f4c9f84b4bd14c999e7e5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/52002 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['input', 'output'],\n",
            "        num_rows: 52002\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "dataset_path_hf = \"lamini/alpaca\"\n",
        "dataset_hf = load_dataset(dataset_path_hf)\n",
        "print(dataset_hf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 81,
        "id": "6Hvd_cPseqKh",
        "outputId": "29aedfe3-23a2-47d8-9f73-c8eeee829167"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LAMINI CONFIGURATION\n",
            "{}\n",
            "LAMINI CONFIGURATION\n",
            "{}\n",
            "LAMINI CONFIGURATION\n",
            "{}\n",
            "Not instruction-tuned output (Llama 2 Base): .\n",
            "Tell me how to train my dog to sit. I have a 10 month old puppy and I want to train him to sit. I have tried the treat method and he just sits there and looks at me like I am crazy. I have tried the \"sit\" command and he just looks at me like I am crazy. I have tried the \"sit\" command and he just looks at me like I am crazy. I have tried the \"sit\" command and he just looks at me like I am crazy. I have tried the \"sit\" command and he just looks at me like I am crazy. I have tried the \"sit\" command and he just looks at me like I am crazy. I have tried the \"sit\" command and he just looks at me like I am crazy. I have tried the \"sit\" command and he just looks at me like I am crazy. I have tried the \"sit\" command and he just looks at me like I am crazy. I have tried the \"sit\" command and he just looks at me like I am crazy. I have tried the \"sit\" command and he just looks at me like I am crazy. I have tried the \"sit\" command and he just looks at me like I am crazy. I have tried the \"sit\" command and he just looks at me like I am crazy. I have tried the \"sit\" command and he just looks at me like I am crazy. I have tried the \"sit\" command and he just looks at me like I am crazy. I have tried the \"sit\" command and he just looks at me like I am crazy. I have tried the \"sit\" command and he just looks at me like I am crazy. I have tried the \"sit\" command and he just looks at me like I am crazy. I have tried the \"sit\" command and he just looks at me like I am crazy. I have tried the \"sit\" command and he just looks at me like I am crazy. I have tried the \"sit\" command and he just looks at me like I am crazy. I have tried the \"sit\" command and he just looks at me like I am crazy. I have tried the \"sit\" command and he just looks at me like I am crazy. I have tried the \"sit\" command and he just looks at me like I am crazy. I have tried the \"sit\" command and he just looks at me like I am crazy. I have tried the \"sit\" command and he just looks at me like I am crazy. I have tried the \"sit\" command and he just looks at me like I am crazy. I have tried the \"sit\" command and he just looks at me like I am crazy. I have tried the \"sit\" command and he just looks at me like I am crazy. I have tried the \"sit\" command and he just looks at me like I am crazy. I have tried the \"sit\" command and he just looks at me like I am crazy. I have tried the \"sit\" command and he just looks at me like I am crazy. I have tried the \"sit\" command and he just looks at me like I am crazy. I have tried the \"sit\" command and he just looks at me like I am crazy. I have tried the \"sit\" command and he just looks at me like I am crazy. I have tried the \"sit\" command and he just looks at me like I am crazy. I have tried the \"sit\" command and he just looks at me like I am crazy. I have tried the \"sit\" command and he just looks at me like I am crazy. I have tried the \"sit\" command and he just looks at me like I am crazy. I have tried the \"sit\" command and he just looks at me like I am crazy. I have tried the \"sit\" command and he just looks at me like I am crazy. I have tried the \"sit\" command and he just looks at me like I am crazy. I have tried the \"sit\" command and he just looks at me like I am crazy. I have tried the \"sit\" command and he just looks at me like I am crazy. I have tried the \"sit\" command and he just looks at me like I am crazy. I have tried the \"sit\" command and he just looks at me like I am crazy. I have tried the \"sit\" command and he just looks at me like I am crazy. I have tried the \"sit\" command and he just looks at me like I am crazy. I have tried the \"sit\" command and he just looks at me like I am crazy. I have tried the \"sit\" command and he just looks at me like I am crazy. I have tried the \"sit\" command and he just looks at me like I am crazy. I have tried the \"sit\" command and he just looks at me like I am crazy. I have tried the \"sit\" command and he just looks at me like I am crazy. I have tried the \"sit\" command and he just looks at me like I am crazy. I have tried the \"sit\" command and he just looks at me like I am crazy. I have tried the \"sit\" command and he just looks at me like I am crazy. I have tried the \"sit\" command and he just looks at me like I am crazy. I have tried the \"sit\" command and he just looks at me like I am crazy. I have tried the \"sit\" command and he just looks at me like I am crazy. I have tried the \"sit\" command and he just looks at me like I am crazy. I have tried the \"sit\" command and he just looks at me like I am crazy. I have tried the \"sit\" command and he just looks at me like I am crazy. I have tried the \"sit\" command and he just looks at me like I am crazy. I have tried the \"sit\" command and he just looks at me like I am crazy. I have tried the \"sit\" command and he just looks at me like I am crazy. I have tried the \"sit\" command and he just looks at me like I am crazy. I have tried the \"sit\" command and he just looks at me like I am crazy. I have tried the \"sit\" command and he just looks at me like I am crazy. I have tried the \"sit\" command and he just looks at me like I am crazy. I have tried the \"sit\" command and he just looks at me like I am crazy. I have tried the \"sit\" command and\n"
          ]
        }
      ],
      "source": [
        "non_instruct_model = BasicModelRunner(\"meta-llama/Llama-2-7b-hf\")\n",
        "non_instruct_output = non_instruct_model(\"Tell me how to train my dog to sit\")\n",
        "print(\"Not instruction-tuned output (Llama 2 Base):\", non_instruct_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 81,
        "id": "JHRzKNx_eqKi",
        "outputId": "4125824a-a834-4f3b-d596-90b0db262bb1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LAMINI CONFIGURATION\n",
            "{}\n",
            "LAMINI CONFIGURATION\n",
            "{}\n",
            "LAMINI CONFIGURATION\n",
            "{}\n",
            "Instruction-tuned output (Llama 2):  on command.\n",
            "Training a dog to sit on command is a basic obedience command that can be achieved with patience, consistency, and positive reinforcement. Here's a step-by-step guide on how to train your dog to sit on command:\n",
            "\n",
            "1. Choose a quiet and distraction-free area: Find a quiet area with minimal distractions where your dog can focus on you.\n",
            "2. Have treats ready: Choose your dog's favorite treats and have them ready to use as rewards.\n",
            "3. Stand in front of your dog: Stand in front of your dog and hold a treat close to their nose.\n",
            "4. Move the treat up and back: Slowly move the treat up and back, towards your dog's tail, while saying \"sit\" in a calm and clear voice.\n",
            "5. Dog will sit: As you move the treat, your dog will naturally sit down to follow the treat. The moment their bottom touches the ground, say \"good sit\" and give them the treat.\n",
            "6. Repeat the process: Repeat steps 3-5 several times, so your dog learns to associate the command \"sit\" with the action of sitting.\n",
            "7. Gradually phase out the treats: As your dog becomes more comfortable with the command, start phasing out the treats. Instead, use praise and affection as rewards.\n",
            "8. Practice, practice, practice: Practice the \"sit\" command in different locations, with different distractions, and at different times of the day. This will help your dog understand that the command is universal and applies in all situations.\n",
            "9. Be consistent: Consistency is key when training a dog. Make sure everyone in the household is using the same command and reward system.\n",
            "10. Be patient: Training a dog takes time and patience. Don't get frustrated if your dog doesn't pick up the command immediately. Keep practicing and eventually, your dog will learn.\n",
            "\n",
            "Remember, training a dog is a journey, and it's important to be patient, consistent, and positive. With time and practice, your dog will learn to sit on command and other basic obedience commands.\n"
          ]
        }
      ],
      "source": [
        "instruct_model = BasicModelRunner(\"meta-llama/Llama-2-7b-chat-hf\")\n",
        "instruct_output = instruct_model(\"Tell me how to train my dog to sit\")\n",
        "print(\"Instruction-tuned output (Llama 2): \", instruct_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIfNzuepeqKi"
      },
      "source": [
        "> Note: This section of the notebook has been updated.\n",
        "\n",
        "Instruction-tuned output (ChatGPT) responds with:\n",
        "\n",
        "> Training your dog to sit is a basic and essential command that can be taught using positive reinforcement. Here's a simple step-by-step guide:\n",
        "> 1. **Prepare Treats:**\n",
        "   Gather small, soft treats that your dog enjoys. Make sure they are easy to chew and won't take too long to eat.\n",
        "> 2. **Find a Quiet Space:**\n",
        "   Choose a quiet area with minimal distractions for the training session. This will help your dog focus better.\n",
        "> 3. **Get Your Dog's Attention:**\n",
        "   Call your dog's name to get their attention. Make sure they are looking at you.\n",
        "> 4. **Use a Treat to Lure:**\n",
        "   Hold a treat close to your dog's nose, and slowly move your hand upward and slightly backward over their head. As you do this, your dog's natural response will be to follow the treat with their nose, causing them to sit.\n",
        "> 5. **Say the Command:**\n",
        "   As your dog starts to sit, say the command \"Sit\" in a clear and firm voice. Use the word consistently every time you want your dog to sit.\n",
        "> 6. **Reward and Praise:**\n",
        "   As soon as your dog sits, immediately reward them with the treat and offer verbal praise. This positive reinforcement will help them associate sitting with positive outcomes.\n",
        "> 7. **Repeat and Practice:**\n",
        "   Repeat the process several times in a row during each training session. Keep the sessions short (around 5-10 minutes) to prevent your dog from losing interest.\n",
        "> 8. **Add Duration:**\n",
        "   Once your dog consistently sits on command, you can gradually increase the duration by waiting a couple of seconds before giving the treat. This helps reinforce the sit command.\n",
        "> 9. **Generalize the Command:**\n",
        "   Practice the \"sit\" command in different locations and with various distractions to help your dog generalize the behavior.\n",
        "> 10. **Be Patient and Consistent:**\n",
        "    Patience and consistency are key in dog training. Always use positive reinforcement, and avoid punishment. If your dog doesn't succeed initially, go back a step and try again.\n",
        ">\n",
        "> Remember that each dog is unique, and some may learn more quickly than others. Adjust your training approach based on your dog's individual needs and progress."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRV9uI3AeqKi"
      },
      "source": [
        "### Try smaller models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 64,
        "id": "6MbKfsS8eqKi",
        "outputId": "adcb8435-cc80-437e-a310-e2a68962798e",
        "colab": {
          "referenced_widgets": [
            "831d6bcd880e4e55bd032de5cb81f9e6",
            "637c92fa377e48299028e74eada50049",
            "2b82f912918d4dd4a95f93418b2dc7b1",
            "246ba02635d142b3b19c844ee195f7e7",
            "38b386190f47432d9683aa966603d7b9"
          ]
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "831d6bcd880e4e55bd032de5cb81f9e6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/396 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "637c92fa377e48299028e74eada50049",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2b82f912918d4dd4a95f93418b2dc7b1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/99.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "246ba02635d142b3b19c844ee195f7e7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/567 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "38b386190f47432d9683aa966603d7b9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/166M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/pythia-70m\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"EleutherAI/pythia-70m\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 421,
        "id": "jptnvYD5eqKj"
      },
      "outputs": [],
      "source": [
        "def inference(text, model, tokenizer, max_input_tokens=1000, max_output_tokens=100):\n",
        "  # Tokenize\n",
        "  input_ids = tokenizer.encode(\n",
        "          text,\n",
        "          return_tensors=\"pt\",\n",
        "          truncation=True,\n",
        "          max_length=max_input_tokens\n",
        "  )\n",
        "\n",
        "  # Generate\n",
        "  device = model.device\n",
        "  generated_tokens_with_prompt = model.generate(\n",
        "    input_ids=input_ids.to(device),\n",
        "    max_length=max_output_tokens\n",
        "  )\n",
        "\n",
        "  # Decode\n",
        "  generated_text_with_prompt = tokenizer.batch_decode(generated_tokens_with_prompt, skip_special_tokens=True)\n",
        "\n",
        "  # Strip the prompt\n",
        "  generated_text_answer = generated_text_with_prompt[0][len(text):]\n",
        "\n",
        "  return generated_text_answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 81,
        "id": "dX_WO2IyeqKj",
        "outputId": "b20cac8c-3564-4e70-cd73-357e3bcb6be5",
        "colab": {
          "referenced_widgets": [
            "fc1ab9337b2d463fad88a930d720b93b",
            "e97067cf0bd64b37afa3586fd4f8a124",
            "80f8e6a18f4846fb8ade762d51be203d",
            "9169a3d546754d7295dfa3eb4e9733df",
            "5e0daf127c1e4b2a99b9c3a4b08cf3b2",
            "63d532d2366d45a2a898bab8dab2d4b1",
            "28a7fa8ff5ec4eb29101884202414732"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fc1ab9337b2d463fad88a930d720b93b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/577 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e97067cf0bd64b37afa3586fd4f8a124",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "80f8e6a18f4846fb8ade762d51be203d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/615k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9169a3d546754d7295dfa3eb4e9733df",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/83.7k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5e0daf127c1e4b2a99b9c3a4b08cf3b2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "63d532d2366d45a2a898bab8dab2d4b1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/1260 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "28a7fa8ff5ec4eb29101884202414732",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating test split:   0%|          | 0/140 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['question', 'answer', 'input_ids', 'attention_mask', 'labels'],\n",
            "        num_rows: 1260\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['question', 'answer', 'input_ids', 'attention_mask', 'labels'],\n",
            "        num_rows: 140\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "finetuning_dataset_path = \"lamini/lamini_docs\"\n",
        "finetuning_dataset = load_dataset(finetuning_dataset_path)\n",
        "print(finetuning_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 98,
        "id": "sGj6xdcieqKj",
        "outputId": "5a92c994-4935-4d44-d786-e029af45a6a4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'question': 'Can Lamini generate technical documentation or user manuals for software projects?', 'answer': 'Yes, Lamini can generate technical documentation and user manuals for software projects. It uses natural language generation techniques to create clear and concise documentation that is easy to understand for both technical and non-technical users. This can save developers a significant amount of time and effort in creating documentation, allowing them to focus on other aspects of their projects.', 'input_ids': [5804, 418, 4988, 74, 6635, 7681, 10097, 390, 2608, 11595, 84, 323, 3694, 6493, 32, 4374, 13, 418, 4988, 74, 476, 6635, 7681, 10097, 285, 2608, 11595, 84, 323, 3694, 6493, 15, 733, 4648, 3626, 3448, 5978, 5609, 281, 2794, 2590, 285, 44003, 10097, 326, 310, 3477, 281, 2096, 323, 1097, 7681, 285, 1327, 14, 48746, 4212, 15, 831, 476, 5321, 12259, 247, 1534, 2408, 273, 673, 285, 3434, 275, 6153, 10097, 13, 6941, 731, 281, 2770, 327, 643, 7794, 273, 616, 6493, 15], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [5804, 418, 4988, 74, 6635, 7681, 10097, 390, 2608, 11595, 84, 323, 3694, 6493, 32, 4374, 13, 418, 4988, 74, 476, 6635, 7681, 10097, 285, 2608, 11595, 84, 323, 3694, 6493, 15, 733, 4648, 3626, 3448, 5978, 5609, 281, 2794, 2590, 285, 44003, 10097, 326, 310, 3477, 281, 2096, 323, 1097, 7681, 285, 1327, 14, 48746, 4212, 15, 831, 476, 5321, 12259, 247, 1534, 2408, 273, 673, 285, 3434, 275, 6153, 10097, 13, 6941, 731, 281, 2770, 327, 643, 7794, 273, 616, 6493, 15]}\n",
            "\n",
            "\n",
            "I have a question about the following:\n",
            "\n",
            "How do I get the correct documentation to work?\n",
            "\n",
            "A:\n",
            "\n",
            "I think you need to use the following code:\n",
            "\n",
            "A:\n",
            "\n",
            "You can use the following code to get the correct documentation.\n",
            "\n",
            "A:\n",
            "\n",
            "You can use the following code to get the correct documentation.\n",
            "\n",
            "A:\n",
            "\n",
            "You can use the following\n"
          ]
        }
      ],
      "source": [
        "test_sample = finetuning_dataset[\"test\"][0]\n",
        "print(test_sample)\n",
        "\n",
        "print(inference(test_sample[\"question\"], model, tokenizer))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ui0xdVl2eqKk"
      },
      "source": [
        "### Compare to finetuned small model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 47,
        "id": "neoaZjV4eqKk",
        "outputId": "0d5cbc18-0da6-482a-e674-6f5c497c4464",
        "colab": {
          "referenced_widgets": [
            "246ca2f5d33d4653ae4aa56b1c2cbdc2",
            "de6561f1187c4855957a7faf83141c0f",
            "42f98a9d22d94355bab6be869a44bf53"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "246ca2f5d33d4653ae4aa56b1c2cbdc2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/717 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "de6561f1187c4855957a7faf83141c0f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/282M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "42f98a9d22d94355bab6be869a44bf53",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "instruction_model = AutoModelForCausalLM.from_pretrained(\"lamini/lamini_docs_finetuned\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 47,
        "id": "hWaX8WY0eqKk",
        "outputId": "008d17ab-b394-4448-fbeb-cba43436aa57"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Yes, Lamini can generate technical documentation or user manuals for software projects. This can be achieved by providing a prompt for a specific technical question or question to the LLM Engine, or by providing a prompt for a specific technical question or question. Additionally, Lamini can be trained on specific technical questions or questions to help users understand the process and provide feedback to the LLM Engine. Additionally, Lamini\n"
          ]
        }
      ],
      "source": [
        "print(inference(test_sample[\"question\"], instruction_model, tokenizer))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 234,
        "id": "mSJMi8I4Sgrw"
      },
      "outputs": [],
      "source": [
        "# Pssst! If you were curious how to upload your own dataset to Huggingface\n",
        "# Here is how we did it\n",
        "\n",
        "# !pip install huggingface_hub\n",
        "# !huggingface-cli login\n",
        "\n",
        "# import pandas as pd\n",
        "# import datasets\n",
        "# from datasets import Dataset\n",
        "\n",
        "# finetuning_dataset = Dataset.from_pandas(pd.DataFrame(data=finetuning_dataset))\n",
        "# finetuning_dataset.push_to_hub(dataset_path_hf)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {}
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbWoGOis4KoG"
      },
      "source": [
        "# Finetuning data: compare to pretraining and basic preparation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets\n",
        "!pip install jsonlines"
      ],
      "metadata": {
        "id": "YPOrGodhRDrG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 132,
        "id": "_LQ5_lop4KJq"
      },
      "outputs": [],
      "source": [
        "import jsonlines\n",
        "import itertools\n",
        "import pandas as pd\n",
        "from pprint import pprint\n",
        "\n",
        "import datasets\n",
        "from datasets import load_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHk6zXRMQ8tL"
      },
      "source": [
        "### Look at pretraining data set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RbgUwKWYQ8tM"
      },
      "source": [
        "**Sorry**, \"The Pile\" dataset is currently relocating to a new home and so we can't show you the same example that is in the video. Here is another dataset, the [\"Common Crawl\"](https://huggingface.co/datasets/c4) dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 98,
        "id": "Qs3vC9j_Q8tM"
      },
      "outputs": [],
      "source": [
        "#pretrained_dataset = load_dataset(\"EleutherAI/pile\", split=\"train\", streaming=True)\n",
        "\n",
        "pretrained_dataset = load_dataset(\"c4\", \"en\", split=\"train\", streaming=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 115,
        "id": "J6-sITJzQ8tM"
      },
      "outputs": [],
      "source": [
        "n = 5\n",
        "print(\"Pretrained dataset:\")\n",
        "top_n = itertools.islice(pretrained_dataset, n)\n",
        "for i in top_n:\n",
        "  print(i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zx6HuQQwQ8tN"
      },
      "source": [
        "### Contrast with company finetuning dataset you will be using"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 81,
        "id": "KVLhQIGvQ8tN"
      },
      "outputs": [],
      "source": [
        "filename = \"lamini_docs.jsonl\"\n",
        "instruction_dataset_df = pd.read_json(filename, lines=True)\n",
        "instruction_dataset_df"
      ]
    },
    {
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "filename = \"lamini_docs.jsonl\"\n",
        "\n",
        "# Read the file line by line and parse each line as JSON\n",
        "data = []\n",
        "with open(filename, 'r') as f:\n",
        "    for line in f:\n",
        "        try:\n",
        "            data.append(json.loads(line))  # Parse the line as JSON\n",
        "        except json.JSONDecodeError as e:\n",
        "            print(f\"Skipping invalid JSON line: {line.strip()}\")\n",
        "            print(f\"Error: {e}\")\n",
        "\n",
        "# Create a Pandas DataFrame from the parsed data\n",
        "instruction_dataset_df = pd.DataFrame(data)\n",
        "\n",
        "instruction_dataset_df"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "5izyVToOSLcs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FvxCgBXQ8tN"
      },
      "source": [
        "### Various ways of formatting your data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 81,
        "id": "aKwAhbLAQ8tN"
      },
      "outputs": [],
      "source": [
        "examples = instruction_dataset_df.to_dict()\n",
        "text = examples[\"question\"][0] + examples[\"answer\"][0]\n",
        "text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 166,
        "id": "4J-IlraiQ8tO"
      },
      "outputs": [],
      "source": [
        "if \"question\" in examples and \"answer\" in examples:\n",
        "  text = examples[\"question\"][0] + examples[\"answer\"][0]\n",
        "elif \"instruction\" in examples and \"response\" in examples:\n",
        "  text = examples[\"instruction\"][0] + examples[\"response\"][0]\n",
        "elif \"input\" in examples and \"output\" in examples:\n",
        "  text = examples[\"input\"][0] + examples[\"output\"][0]\n",
        "else:\n",
        "  text = examples[\"text\"][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 98,
        "id": "coD5U__eQ8tO"
      },
      "outputs": [],
      "source": [
        "prompt_template_qa = \"\"\"### Question:\n",
        "{question}\n",
        "\n",
        "### Answer:\n",
        "{answer}\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 115,
        "id": "FnS_GI0zQ8tO"
      },
      "outputs": [],
      "source": [
        "question = examples[\"question\"][0]\n",
        "answer = examples[\"answer\"][0]\n",
        "\n",
        "text_with_prompt_template = prompt_template_qa.format(question=question, answer=answer)\n",
        "text_with_prompt_template"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 81,
        "id": "heVPG2AhQ8tO"
      },
      "outputs": [],
      "source": [
        "prompt_template_q = \"\"\"### Question:\n",
        "{question}\n",
        "\n",
        "### Answer:\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 234,
        "id": "pmotPiatQ8tP"
      },
      "outputs": [],
      "source": [
        "num_examples = len(examples[\"question\"])\n",
        "finetuning_dataset_text_only = []\n",
        "finetuning_dataset_question_answer = []\n",
        "for i in range(num_examples):\n",
        "  question = examples[\"question\"][i]\n",
        "  answer = examples[\"answer\"][i]\n",
        "\n",
        "  text_with_prompt_template_qa = prompt_template_qa.format(question=question, answer=answer)\n",
        "  finetuning_dataset_text_only.append({\"text\": text_with_prompt_template_qa})\n",
        "\n",
        "  text_with_prompt_template_q = prompt_template_q.format(question=question)\n",
        "  finetuning_dataset_question_answer.append({\"question\": text_with_prompt_template_q, \"answer\": answer})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 30,
        "id": "ZrnDNKiyQ8tP"
      },
      "outputs": [],
      "source": [
        "pprint(finetuning_dataset_text_only[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 47,
        "id": "BqVKaJMVQ8tP"
      },
      "outputs": [],
      "source": [
        "pprint(finetuning_dataset_question_answer[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfyaYVKrQ8tP"
      },
      "source": [
        "### Common ways of storing your data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 64,
        "id": "J-FTD3CYQ8tP"
      },
      "outputs": [],
      "source": [
        "with jsonlines.open(f'lamini_docs_processed.jsonl', 'w') as writer:\n",
        "    writer.write_all(finetuning_dataset_question_answer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 81,
        "id": "WusEbQKIQ8tP"
      },
      "outputs": [],
      "source": [
        "finetuning_dataset_name = \"lamini/lamini_docs\"\n",
        "finetuning_dataset = load_dataset(finetuning_dataset_name)\n",
        "print(finetuning_dataset)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}